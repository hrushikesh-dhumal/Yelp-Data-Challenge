{
  "name": "Yelp-data-challenge",
  "tagline": "sentiment analysis in yelp data",
  "body": "# Introduction\r\n***\r\n\r\nWith the explosion of social media, more and more people are blogging and writing reviews about different places they visit. Yelp is one the popular platform where people post their ratings and write reviews. User-generated reviews are usually inconsistent in terms of length, content, writing style and usefulness because they are written by unprofessional writers. Also, they contain a mix of positive and negative emotions. Important information can be easily obscured unless users are willing to spend a great deal of time and effort on reading the reviews thoroughly. A common natural language processing technique is to generate bag of words and use that for analysis. But, it does not account for the positive or negative sentiment of the user. So I am using the word embedding approach to understand how neural networks can help us better identify the sentiments in the reviews. I am considering the five start ratings by user as the parameter to measure the degree of positivity or negativity in the review. One being the most negative and five being the most positive review. Through this work, I hope to encourage more researchers to study and analyze the Yelp data set.\r\n\r\n[This repository](https://github.com/hrushikesh-dhumal/Yelp-Data-Challenge) has my code and a sample data set to play around. The project is broken into 3 parts: \r\n\r\n# Data Cleaning\r\n***\r\n \r\n1. Converted data from json file to flat format- csv.  \r\n2. Identified and removed features with null values.  \r\n3. Inner-joined key-ids from Users, Businesses and Review tables to create the master data set with 22,25,213 records.  \r\n4. Created a random subset of 2,225 records. I have provided this subset in the repository. \r\n\r\n# Exploratory Data Analysis\r\n***\r\n\r\nIn EDA, I am trying to find pertinent features for the next step which is the predictive analytics/machine learning task. \r\n![Review star distribution](https://raw.githubusercontent.com/hrushikesh-dhumal/Yelp-Data-Challenge/gh-pages/images/Review_star_distribution.png)\r\n\r\n\r\nWhen I visualized distribution of star rating, I was surprised to see it was skewed to the 4 and 5 star categories heavily. They consist of around 80% of the distribution, whereas the 1, 2, and 3 star categories are each only around 10-15% at most.  This is confirmed by a separate  analysis by Max Woolf on 1 and 5 star reviews which showed, that Yelp reviews have started to appear more optimistically biased as time passes. The data subset reflects this skewed distribution, and uneven class distribution will become noteworthy further on in our predictive analytics task.\r\nWe used this information to set our baseline accuracy for algorithm evaluation to 40% which is the percentage of 5 star ratings in the data. \r\n\r\n\r\nNext I was curious about what kinds of words, are characteristic of different star categories so I did some word cloud visualizations. \r\n\r\n![Word cloud for one star reviews](https://raw.githubusercontent.com/hrushikesh-dhumal/Yelp-Data-Challenge/gh-pages/images/Wordcloud_1_star.png)  \r\nThe 1-star Yelp reviews use very little positive language, for eg: “Horrible” and “Worst”. 1-Star reviews frequently contain warnings for potential customers, which promises that the author will “never go back”. _Sometime we see sarcasm in form of words like “wow” and “love” used in 1 star rating._ \r\n\r\n![Word cloud for two stars reviews](https://raw.githubusercontent.com/hrushikesh-dhumal/Yelp-Data-Challenge/gh-pages/images/Wordcloud_2_star.png)\r\n \r\n![Word cloud for three stars reviews](https://raw.githubusercontent.com/hrushikesh-dhumal/Yelp-Data-Challenge/gh-pages/images/Wordcloud_3_star.png)\r\n\r\n ![Word cloud for four stars reviews](https://raw.githubusercontent.com/hrushikesh-dhumal/Yelp-Data-Challenge/gh-pages/images/Wordcloud_4_star.png)\r\n\r\n![Word cloud for five stars reviews](https://raw.githubusercontent.com/hrushikesh-dhumal/Yelp-Data-Challenge/gh-pages/images/Wordcloud_5_star.png)\r\n\r\nThe 5-star Yelp reviews contain many instances of “Great”, “Good”, and “best”. But reviewers are also using positive words sarcastically to indicate negative sentiments. This inspired me to use neural networks in form of word embedding's and Long Short term Memory neural networks.\r\n\r\nFurther, to see if Yelp reviews follow the [Zipfs Law](https://en.wikipedia.org/wiki/Zipf%27s_law) I created the following visualization to see how the most frequently occurring words are ranked.  \r\n![Zipfs plot](https://raw.githubusercontent.com/hrushikesh-dhumal/Yelp-Data-Challenge/gh-pages/images/Zipfs_plot.png)\r\n\r\n\r\nThe plot basically shows the log of rank i.e. descending order of how frequently is a word occurring in the yelp corpus Vs log of the frequency of word. I can see that it is almost a straight line indicating that even Yelp corpus focus the Zipfs law! To further enhance the understanding I have created an interactive visualization where you can see the frequency of word vs rank plot. \r\n\r\n<p>\r\n<iframe width=\"900\" height=\"800\" frameborder=\"0\" scrolling=\"no\" src=\"https://plot.ly/~hrushikesh-dhumal/36.embed\"></iframe>\r\n</p>\r\n\r\nI see that words such as the, it which are repeated more prominently and need to be removed. \r\n\r\n# Predictive analytics/machine learning \r\n***\r\n\r\n\r\n\r\n# Author Information\r\n***  \r\n\r\nHrushikesh Dhumal(hrushikesh.dhumal@gmail.com)\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}